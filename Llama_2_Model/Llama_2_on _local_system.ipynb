{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f77feae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1aaa79ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144b56f66cdd4ac89d015ac630662cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the disk.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",device_map='auto',use_auth_token='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')\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\",use_auth_token='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')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "141c87a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama2_reponse(prompt, max_new_tokens=50):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, temperature= 0.00001)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea91b8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navneetyadav/anaconda3/lib/python3.11/site-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on mps. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('mps') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Q. What is the capital of India?\n",
      "A. The capital of India is New Delhi.\n",
      "\n",
      "Q. What is the currency of India?\n",
      "A. The currency of India is Indian rupee (INR).\n",
      "\n",
      "Q. What is the official language of India\n",
      "1147.7952950000763\n"
     ]
    }
   ],
   "source": [
    "st=time.time()\n",
    "prompt = \"Q. What is the capital of India?\"\n",
    "res=get_llama2_reponse(prompt, max_new_tokens=50)\n",
    "et=time.time()\n",
    "print(res)\n",
    "print(et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4557075d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navneetyadav/anaconda3/lib/python3.11/site-packages/transformers/generation/utils.py:1468: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on mps. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('mps') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep answer short Q. What is the capital of India?\n",
      "A. New Delhi\n",
      "B. Mumbai\n",
      "C. Bengaluru\n",
      "D. Kolkata\n",
      "\n",
      "Answer: A. New Delhi\n",
      "792.8908569812775\n"
     ]
    }
   ],
   "source": [
    "st=time.time()\n",
    "prompt = \"Keep answer short Q. What is the capital of India?\"\n",
    "res=get_llama2_reponse(prompt, max_new_tokens=50)\n",
    "et=time.time()\n",
    "print(res)\n",
    "print(et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2e07f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/navneetyadav/anaconda3/lib/python3.12/site-packages/transformers/generation/utils.py:1510: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on mps. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('mps') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give only the answer Q. What is the capital of India?\n",
      "A. New Delhi\n",
      "B. Mumbai\n",
      "C. Kolkata\n",
      "D. Chennai\n",
      "585.8944878578186\n"
     ]
    }
   ],
   "source": [
    "st=time.time()\n",
    "prompt = \"Give only the answer Q. What is the capital of India?\"\n",
    "res=get_llama2_reponse(prompt, max_new_tokens=50)\n",
    "et=time.time()\n",
    "print(res)\n",
    "print(et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b78a1f4a-3bcf-46ef-bde7-dbfa1ad27d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama2_reponse(prompt, max_new_tokens=50):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, temperature= 0.001)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1697243-517f-4dde-9842-ffcc6366c5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q. What is the capital of India?\n",
      "A. The capital of India is New Delhi.\n",
      "\n",
      "Q. What is the currency of India?\n",
      "A. The currency of India is Indian rupee (INR).\n",
      "\n",
      "Q. What is the official language of India\n",
      "1169.768721818924\n"
     ]
    }
   ],
   "source": [
    "st=time.time()\n",
    "prompt = \"Q. What is the capital of India?\"\n",
    "res=get_llama2_reponse(prompt, max_new_tokens=50)\n",
    "et=time.time()\n",
    "print(res)\n",
    "print(et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bceb58c5-8813-44dc-813b-ff1a605c8cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama2_reponse(prompt, max_new_tokens=50):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, temperature= 0.00001)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "436649bb-5108-451e-a2a3-62f7e63dc337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the meaning of Hindi name \"Navneet\" नवनीत?\n",
      "\n",
      "Navneet is a Hindi name that means \"new, fresh, or pure\". It is a popular name for both boys and girls in India and is often given to children born in the month of Nav\n",
      "1234.7757730484009\n"
     ]
    }
   ],
   "source": [
    "st=time.time()\n",
    "prompt = \"What is the meaning of Hindi name \\\"Navneet\\\" \"\n",
    "res=get_llama2_reponse(prompt, max_new_tokens=50)\n",
    "et=time.time()\n",
    "print(res)\n",
    "print(et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32c01d51-44fb-4a5b-96c4-8fdcaa9c5df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama2_reponse(prompt, max_new_tokens=50):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, temperature= 1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6df50875-c2b5-4768-a24c-250756741184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keep answer short Q. What is the capital of India? A. New Delhi\n",
      "\n",
      "Keep answer short\n",
      "\n",
      "Q. What is the capital of India?\n",
      "A. New Delhi\n",
      "691.5691759586334\n"
     ]
    }
   ],
   "source": [
    "st=time.time()\n",
    "prompt = \"Keep answer short Q. What is the capital of India?\"\n",
    "res=get_llama2_reponse(prompt, max_new_tokens=50)\n",
    "et=time.time()\n",
    "print(res)\n",
    "print(et-st)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6d7d59-33e5-448c-aae9-a29fb2f4b1d9",
   "metadata": {},
   "source": [
    "# with time function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee11a438-9e1f-4787-9654-d25a0f2d66b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama2_reponse(prompt, max_new_tokens=50):\n",
    "    st=time.time()\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, temperature= 1)\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    et=time.time()\n",
    "    time_taken=et-st\n",
    "    return response,time_taken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e4d031-4d7e-4c86-8c34-ce774ed28d9b",
   "metadata": {},
   "source": [
    "# Prompt given by Nitin Sir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1336b6c4-4d37-431d-bbc7-3be6f41099ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\" Analyze a BPO customer care call transcript step by step.\n",
    "The transcript might contain incomplete or unclear sentences.\n",
    "Analyze the conversation between the customer and the customer service representative (CSR) to derive insights into their communication skills, problem-solving abilities, and adherence to company policies and procedures.\n",
    "Identify any issues raised by the customer and evaluate how effectively the CSR addressed them.\n",
    "Pay attention to the tone and language used by both parties to assess their professionalism and empathy.\n",
    "Consider the overall outcome of the call, including whether the customer's concerns were resolved satisfactorily and if the CSR followed up appropriately.\n",
    "\n",
    "Additional Information to Consider:\n",
    "1) CSR Identified Self and Client Utilizing Approved Script\n",
    "2) Rephrased the Customer Inquiry or Need\n",
    "3) Demonstrated Empathy and/or a Desire to Assist\n",
    "4) Captured Caller Information (Name, Address, Phone Number, E-Mail)\n",
    "5) Confirmed Spelling and Numbers\n",
    "6) Captured Product Data / Followed CRM Procedural Guidelines\n",
    "7) Remained Professional and Polite Throughout Call\n",
    "8) Spoke Confidently and Knowledgeably Throughout the Call\n",
    "9) Tone was Upbeat and Warm\n",
    "10) Conversation was Engaging, Not Mechanical and Personalized to the Caller\n",
    "11) Appropriate Pace / Mirrored the Caller\n",
    "12) Refrained from Negative terms, Internal Jargon, or Slang\n",
    "13) Refrained from Interrupting the Caller\n",
    "14) Prevented Dead Air by Making Positive Conversation\n",
    "15) Spoke Clearly, Without Filler Words (Um, Yeah, O\n",
    "\n",
    "Customer Care call for which to analyze: good morning I'm wondering how products arrived I ordered calcium tablets from Amazon and there is no safety seal to break before I would open up and remove the inner seal do you is that how your product arrives or is close to have an outer seal as well I can look into that for you just what is the product number of do you have the lot number on the bottle 2553188 553188 correct thank you very much thank you very much I really appreciate it thank you should they got Captain tablets from Amazon and they're wondering if there's supposed to be an outer seal on the product toxic waste over the inner seal should be intact and the product should be safe okay looks like the inter text so I feel safe using it thank you for your help I really appreciate it wonderful no you are wonderful thanks a million and I hope you have a wonderful sunny day out there and please send some of that Sunshine here it's pouring down rain on the East Coast thank you very much have a wonderful Easter there is a two question survey at the end of the call do I need your name Walter okay thank you Walter appreciate my pleasure thank you very much for your assistance\"\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "948625a0-13df-4972-b44d-e8876635cf1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Analyze a BPO customer care call transcript step by step.\\nThe transcript might contain incomplete or unclear sentences.\\nAnalyze the conversation between the customer and the customer service representative (CSR) to derive insights into their communication skills, problem-solving abilities, and adherence to company policies and procedures.\\nIdentify any issues raised by the customer and evaluate how effectively the CSR addressed them.\\nPay attention to the tone and language used by both parties to assess their professionalism and empathy.\\nConsider the overall outcome of the call, including whether the customer\\'s concerns were resolved satisfactorily and if the CSR followed up appropriately.\\n\\nAdditional Information to Consider:\\n1) CSR Identified Self and Client Utilizing Approved Script\\n2) Rephrased the Customer Inquiry or Need\\n3) Demonstrated Empathy and/or a Desire to Assist\\n4) Captured Caller Information (Name, Address, Phone Number, E-Mail)\\n5) Confirmed Spelling and Numbers\\n6) Captured Product Data / Followed CRM Procedural Guidelines\\n7) Remained Professional and Polite Throughout Call\\n8) Spoke Confidently and Knowledgeably Throughout the Call\\n9) Tone was Upbeat and Warm\\n10) Conversation was Engaging, Not Mechanical and Personalized to the Caller\\n11) Appropriate Pace / Mirrored the Caller\\n12) Refrained from Negative terms, Internal Jargon, or Slang\\n13) Refrained from Interrupting the Caller\\n14) Prevented Dead Air by Making Positive Conversation\\n15) Spoke Clearly, Without Filler Words (Um, Yeah, O\\n\\nCustomer Care call for which to analyze: good morning I\\'m wondering how products arrived I ordered calcium tablets from Amazon and there is no safety seal to break before I would open up and remove the inner seal do you is that how your product arrives or is close to have an outer seal as well I can look into that for you just what is the product number of do you have the lot number on the bottle 2553188 553188 correct thank you very much thank you very much I really appreciate it thank you should they got Captain tablets from Amazon and they\\'re wondering if there\\'s supposed to be an outer seal on the product toxic waste over the inner seal should be intact and the product should be safe okay looks like the inter text so I feel safe using it thank you for your help I really appreciate it wonderful no you are wonderful thanks a million and I hope you have a wonderful sunny day out there and please send some of that Sunshine here it\\'s pouring down rain on the East Coast thank you very much have a wonderful Easter there is a two question survey at the end of the call do I need your name Walter okay thank you Walter appreciate my pleasure thank you very much for your assistance\"\\n\\n\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e571508-ab9a-4160-afd1-316e2ab5c4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "st=time.time()\n",
    "res=get_llama2_reponse(prompt, max_new_tokens=50)\n",
    "et=time.time()\n",
    "print(res)\n",
    "print(et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe6b01e-32f4-471c-bc30-31cbcc23cc95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
